{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn.1_simpleRNNtest_LSTM_GRU_outputs_GColab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Experimento com RNN: Verificar saídas e estados do LSTM e GRU para diferentes argumentos de entrada**"
      ],
      "metadata": {
        "id": "p4z1Axzf4Vwf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eikfzi8ZT_rW"
      },
      "source": [
        "# **Recurrent Neural Networks (RNN) applied to Natural Language Processing (NLP)**\n",
        "\n",
        "- Neste projeto, vamos **avaliar os efeitos relacionados à utilização de diferentes argumentos ao se invocar o GRU ou LSTM**.\n",
        "- Em particular, podemos passar como argumento `return_sequences = True`, que fará o sistema retornar as saídas de cada ponto no tempo, ao invés de apenas a última saída.\n",
        "- Também podemos passar `return_states = True`, o que fará o sistema retornar os estados das camadas ocultas (hidden states) em adição à saída da rede.\n",
        "- Ao se trabalhar com uma API Machine Learning, uma das coisas mais importantes é compreender o formato de cada uma das entradas e saídas.\n",
        "\n",
        "Neste projeto, **vamos provar que, dependendo da unidade recursiva utilizada, o hidden state será exatamente igual à saída** (`hidden state = output`)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importar bibliotecas para análise**"
      ],
      "metadata": {
        "id": "sLmPin6ig-eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://deeplearningcourses.com/c/deep-learning-advanced-nlp\n",
        "from __future__ import print_function, division\n",
        "from builtins import range, input\n",
        "# Note: you may need to update your version of future\n",
        "# sudo pip install -U future\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "  import keras.backend as K\n",
        "  if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
        "    from keras.layers import CuDNNLSTM as LSTM\n",
        "    from keras.layers import CuDNNGRU as GRU\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "k5LC3b1ag8dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configurações de parâmetros de forma dos dados**"
      ],
      "metadata": {
        "id": "LhqIspfRhvS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "- T = sequence length (number of words);\n",
        "- D = input dimensionality (size of the word vectors);\n",
        "- M = hidden layer size;\n",
        "- K = number of output classes.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "6nRts0mscvBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T = 8\n",
        "D = 2\n",
        "M = 3"
      ],
      "metadata": {
        "id": "eI_tusKJh0L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos criar também dados de entrada aleatórios.\n",
        "- Esta amostra será uma matriz de números aleatórios entre -1 a 1, de dimensão T x D, criada com a correspondente função do NumPy."
      ],
      "metadata": {
        "id": "vce7XMjfdO7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randn(1, T, D)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CPHlYcSdhhF",
        "outputId": "56ffffe1-6f22-4feb-a00e-054b3e0a8632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0.17128711  0.02895866]\n",
            "  [ 0.08442127 -1.4335657 ]\n",
            "  [-0.50074148 -0.91084879]\n",
            "  [ 1.07310412  0.13638003]\n",
            "  [-1.39514574 -1.14349911]\n",
            "  [ 0.21751521  0.67588334]\n",
            "  [-0.9521634  -1.00280792]\n",
            "  [-0.14377812 -0.99916313]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta matriz poderia ser a **representação de uma única sequência de vetores de palavras, ou poderia ser algum outro sinal obtido**."
      ],
      "metadata": {
        "id": "Xv7SUNdedwf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Primeiro experimento LSTM: Função lstm1** \n",
        "\n",
        "- A primeira coisa que fazemos aqui é criar nossa camada de input (input layer), de dimensão T x D, e passamos os dados, a seguir, pela camada LSTM.\n",
        "- Na criação da camada LSTM, passamos o argumento `return_state = True`.\n",
        "- Lembre-se que temos, no LSTM, dois estados, h (hidden) e c (cell). \n",
        "- Quando criamos um modelo que mais tarde realizará previsões (ou seja, que retornará a saída do LSTM), precisamos ser capazes de capturar 3 saídas diferentes:\n",
        "\n",
        "  1) A saída de fato do LSTM;\n",
        "  \n",
        "  2) Hidden state (h); e\n",
        "  \n",
        "  3) Cell state (c)."
      ],
      "metadata": {
        "id": "0d6Xy9QThLJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm1():\n",
        "  input_ = Input(shape=(T, D))\n",
        "  rnn = LSTM(M, return_state=True)\n",
        "  x = rnn(input_)\n",
        "\n",
        "  model = Model(inputs=input_, outputs=x)\n",
        "  o, h, c = model.predict(X)\n",
        "  print(\"o:\", o)\n",
        "  print(\"h:\", h)\n",
        "  print(\"c:\", c)"
      ],
      "metadata": {
        "id": "-BqPny8GffMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Segundo experimento LSTM: Função lstm2** \n",
        "\n",
        "- A função é igual à lstm1. A única diferença é que também passamos o argumento:\n",
        "\n",
        "```\n",
        "return_sequences=True\n",
        "```\n",
        "- O objetivo deste experimento é verificar quais saídas serão retornadas, e como estas saídas se relacionam ao que ocorre quando o parâmetro está em seu valor-padrão, `False`."
      ],
      "metadata": {
        "id": "rBt7xtXUftEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm2():\n",
        "  input_ = Input(shape=(T, D))\n",
        "  rnn = LSTM(M, return_state=True, return_sequences=True)\n",
        "  # rnn = GRU(M, return_state=True)\n",
        "  x = rnn(input_)\n",
        "\n",
        "  model = Model(inputs=input_, outputs=x)\n",
        "  o, h, c = model.predict(X)\n",
        "  print(\"o:\", o)\n",
        "  print(\"h:\", h)\n",
        "  print(\"c:\", c)"
      ],
      "metadata": {
        "id": "0BIv3pyDfoNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Primeiro experimento GRU: Função GRU1** \n",
        "\n",
        "- Esta função espelha a função lstm1, quando substituímos LSTM por GRU.\n",
        "- Lembre-se que o GRU possui apenas 1 estado, h.\n",
        "- Portanto, quando evocamos a previsão do modelo (`model.predict(X)`), **são retornados apenas 2 valores ao invés dos 3 valores de saída retornados pelo LSTM**."
      ],
      "metadata": {
        "id": "PfGG7mBTfwqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gru1():\n",
        "  input_ = Input(shape=(T, D))\n",
        "  rnn = GRU(M, return_state=True)\n",
        "  x = rnn(input_)\n",
        "\n",
        "  model = Model(inputs=input_, outputs=x)\n",
        "  o, h = model.predict(X)\n",
        "  print(\"o:\", o)\n",
        "  print(\"h:\", h)"
      ],
      "metadata": {
        "id": "x9GOQUqUfxO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Segundo experimento GRU: Função GRU2** \n",
        "\n",
        "- Esta função espelha a função lstm2, quando substituímos LSTM por GRU.\n",
        "- Assim, aqui temos `return_state=True` e `return_sequences=True`.\n",
        "- Mais uma vez, como o GRU possui apenas 1 estado (h), são retornados apenas 2 valores."
      ],
      "metadata": {
        "id": "mu2BAvi-f0XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gru2():\n",
        "  input_ = Input(shape=(T, D))\n",
        "  rnn = GRU(M, return_state=True, return_sequences=True)\n",
        "  x = rnn(input_)\n",
        "\n",
        "  model = Model(inputs=input_, outputs=x)\n",
        "  o, h = model.predict(X)\n",
        "  print(\"o:\", o)\n",
        "  print(\"h:\", h)"
      ],
      "metadata": {
        "id": "20nwHroaf0se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que o comando `model.predict(X)` calcula os valores previstos pelo modelo `model` para cada um dos valores do dataframe `X` fornecido como input."
      ],
      "metadata": {
        "id": "SiidlfmfEWMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"lstm1:\")\n",
        "lstm1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh-_z7-vf4dX",
        "outputId": "6b9fbd31-cd70-44b0-c1dc-3dfbefe377d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lstm1:\n",
            "o: [[-0.17164306 -0.14928916 -0.18100695]]\n",
            "h: [[-0.17164306 -0.14928916 -0.18100695]]\n",
            "c: [[-0.46857202 -0.25278148 -0.50404453]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui no lstm1 nós retornamos os estados, mas nenhuma sequência.\n",
        "- Note que **a saída o (\"output\") é exatamente igual a h (\"hidden state)**.\n",
        "- Portanto, para o LSTM, h = o, o que desejávamos verificar."
      ],
      "metadata": {
        "id": "C7JUB_r7jtO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"lstm2:\")\n",
        "lstm2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX7ilZ8Gf-5h",
        "outputId": "b5621b61-643b-4d27-fa6f-78d05d6c7351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lstm2:\n",
            "o: [[[ 0.02380813 -0.02079004 -0.01417855]\n",
            "  [-0.05204503  0.09870689 -0.05733851]\n",
            "  [-0.10372683  0.16380192 -0.05819457]\n",
            "  [ 0.1137677  -0.06495867 -0.1178459 ]\n",
            "  [-0.04452203  0.03250882  0.00755201]\n",
            "  [ 0.02075053 -0.07436121  0.01028471]\n",
            "  [-0.07959417  0.0269038   0.06434048]\n",
            "  [-0.11766418  0.12295073  0.02959999]]]\n",
            "h: [[-0.11766418  0.12295073  0.02959999]]\n",
            "c: [[-0.22961718  0.19231719  0.0732884 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Veja que h e c são exatamente iguais no lstm1 e lstm2.\n",
        "- Porém, a saída o é maior em lstm2, função na qual passamos como argumento o comando de retornar as sequências.\n",
        "- Note que o é formado por uma sequência de 8 arrays. Isto ocorre porque, lembrando das definições de parâmetros no começo do notebook: `T = 8`.\n",
        "- Repare ainda que o último elemento de o é igual ao hidden state h. Quando definimos `return_sequences=False (lstm1)`, apenas este último array é retornado em o.\n",
        "- Assim, **h e c representam, na realidade, os hidden states finais do LSTM**.\n",
        "- Em outras palavras, **h e c são o hidden state e o cell state no último passo temporal do input**."
      ],
      "metadata": {
        "id": "igz8yUM_kPJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"gru1:\")\n",
        "gru1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HptjE5zUgDoT",
        "outputId": "bc30d7f0-f6f9-479d-a6e6-9b7497020f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gru1:\n",
            "o: [[-0.41285896  0.13199161 -0.19100542]]\n",
            "h: [[-0.41285896  0.13199161 -0.19100542]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui a observação é a mesma feita para o lstm1: como a saída o contém apenas o último estágio temporal (valor final), o (\"output\") e h (\"hidden state\") são iguais."
      ],
      "metadata": {
        "id": "79Pdj0Melgo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"gru2:\")\n",
        "gru2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRjuKP5FgG4B",
        "outputId": "d4d376f4-695f-4a43-ec4a-9572b7496a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gru2:\n",
            "o: [[[ 0.05330895  0.05650215  0.02914332]\n",
            "  [ 0.0646524   0.09152526 -0.11673455]\n",
            "  [-0.13698067 -0.02340787 -0.20172621]\n",
            "  [ 0.16627601  0.3503932   0.18803528]\n",
            "  [-0.3561732   0.06852631 -0.03838757]\n",
            "  [-0.12937838  0.06368127  0.10767905]\n",
            "  [-0.37870485 -0.11547271 -0.08032594]\n",
            "  [-0.19312723 -0.11588701 -0.11327047]]]\n",
            "h: [[-0.19312723 -0.11588701 -0.11327047]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assim como no lstm2, novamente temos uma saída o formada por 8 arrays, consequência da definição `T = 8`. Além disso, o último elemento de o é igual ao hidden state h. Quando definimos `return_sequences=False (gru1)`, apenas este último array é retornado em o."
      ],
      "metadata": {
        "id": "EVhgwPngluz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusão**\n",
        "\n",
        "- O objetivo deste notebook é ilustrar as diferentes saídas (\"output\", o) e estados (\"hidden state\", h, e \"cell state\", c) retornados pelo sistema quando definimos `return_state = True` ou `return_sequences = True`.\n",
        "- Em notebooks mais complexos sobre RNN, volte aqui para recordar as saídas e estados esperados, bem como as respectivas interpretações.\n",
        "- Uma técnica útil para o \"debug\" da rede neural é verificar se tudo está no formato/dimensão correta a cada etapa de cálculo.\n",
        "- Muitas vezes, **perdemos esta granularidade ao utilizar operações de agregação como Pooling ou soma das médias**. Este caso é particularmente difícil de ser corrigido, pois o sistema retorna um valor incorreto ao invés de uma mensagem de erro, podendo passar a impressão que o código está correto quando não o está."
      ],
      "metadata": {
        "id": "qrgqA1NBmSHj"
      }
    }
  ]
}